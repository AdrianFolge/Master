{'text_splitter': <langchain_experimental.text_splitter.SemanticChunker object at 0x135cfa0d0>, 'embedding model': HuggingFaceEmbeddings(client=SentenceTransformer(
  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: XLMRobertaModel 
  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})
), model_name='sentence-transformers/paraphrase-multilingual-mpnet-base-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False), 'score': {'context_precision': 0.7500, 'faithfulness': 0.9663, 'answer_relevancy': 0.7865, 'context_recall': 0.9375}}
{'text_splitter': <langchain_experimental.text_splitter.SemanticChunker object at 0x135cfa0d0>, 'embedding model': HuggingFaceEmbeddings(client=SentenceTransformer(
  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: XLMRobertaModel 
  (1): Pooling({'word_embedding_dimension': 1024, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})
  (2): Normalize()
), model_name='intfloat/multilingual-e5-large', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False), 'score': {'context_precision': 0.8000, 'faithfulness': 0.9542, 'answer_relevancy': 0.7804, 'context_recall': 0.9750}}
{'text_splitter': <langchain_experimental.text_splitter.SemanticChunker object at 0x135cfa0d0>, 'embedding model': OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x14f96d050>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x14d64b190>, model='text-embedding-3-large', dimensions=None, deployment='text-embedding-ada-002', openai_api_version='', openai_api_base=None, openai_api_type='', openai_proxy='', embedding_ctx_length=8191, openai_api_key=SecretStr('**********'), openai_organization=None, allowed_special=set(), disallowed_special='all', chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None), 'score': {'context_precision': 0.8500, 'faithfulness': 0.9750, 'answer_relevancy': 0.8219, 'context_recall': 0.9375}}
{'text_splitter': <langchain_text_splitters.character.RecursiveCharacterTextSplitter object at 0x134443e10>, 'embedding model': HuggingFaceEmbeddings(client=SentenceTransformer(
  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: XLMRobertaModel 
  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})
), model_name='sentence-transformers/paraphrase-multilingual-mpnet-base-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False), 'score': {'context_precision': 0.9500, 'faithfulness': 0.9817, 'answer_relevancy': 0.8528, 'context_recall': 0.8625}}
{'text_splitter': <langchain_text_splitters.character.RecursiveCharacterTextSplitter object at 0x134443e10>, 'embedding model': HuggingFaceEmbeddings(client=SentenceTransformer(
  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: XLMRobertaModel 
  (1): Pooling({'word_embedding_dimension': 1024, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})
  (2): Normalize()
), model_name='intfloat/multilingual-e5-large', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False), 'score': {'context_precision': 0.9500, 'faithfulness': 0.9737, 'answer_relevancy': 0.8310, 'context_recall': 0.8750}}
{'text_splitter': <langchain_text_splitters.character.RecursiveCharacterTextSplitter object at 0x134443e10>, 'embedding model': OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x14f96d050>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x14d64b190>, model='text-embedding-3-large', dimensions=None, deployment='text-embedding-ada-002', openai_api_version='', openai_api_base=None, openai_api_type='', openai_proxy='', embedding_ctx_length=8191, openai_api_key=SecretStr('**********'), openai_organization=None, allowed_special=set(), disallowed_special='all', chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None), 'score': {'context_precision': 0.9500, 'faithfulness': 0.9692, 'answer_relevancy': 0.8380, 'context_recall': 0.8375}}
{'text_splitter': <langchain_text_splitters.character.CharacterTextSplitter object at 0x134c69a90>, 'embedding model': HuggingFaceEmbeddings(client=SentenceTransformer(
  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: XLMRobertaModel 
  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})
), model_name='sentence-transformers/paraphrase-multilingual-mpnet-base-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False), 'score': {'context_precision': 0.9000, 'faithfulness': 0.9645, 'answer_relevancy': 0.8606, 'context_recall': 0.8875}}
