{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag_models.naive_rag import naive_rag_translated\n",
    "from init_vectorstore import init_vectorstore\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from ragas_func import ragas_with_params\n",
    "import os\n",
    "from deep_translator import GoogleTranslator\n",
    "from langchain_text_splitters import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"OPENAI_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = 20\n",
    "file_path = \"./data/synthetic_data/version_3_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "references = load_dataset('csv', data_files=file_path, split=f\"train[:{instances}]\")\n",
    "refs = references[\"svar\"]\n",
    "questions = references[\"spørsmål\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_translated = []\n",
    "for question in questions:\n",
    "    translated_question = GoogleTranslator(source='no', target='en').translate(text=question)\n",
    "    questions_translated.append(translated_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recursive_text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "character_text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "semantic_text_splitter = SemanticChunker(\n",
    "    OpenAIEmbeddings(), breakpoint_threshold_type=\"percentile\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_para = SentenceTransformerEmbeddings(model_name='sentence-transformers/paraphrase-multilingual-mpnet-base-v2')\n",
    "embeddings_multiling = SentenceTransformerEmbeddings(model_name='intfloat/multilingual-e5-large')\n",
    "embeddings_openai = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitters = [recursive_text_splitter, character_text_splitter]\n",
    "embeddings = [embeddings_para, embeddings_multiling, embeddings_openai]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_scores = []\n",
    "for text_splitter in text_splitters:\n",
    "    for embedding in embeddings:\n",
    "        databases = init_vectorstore(embedding, text_splitter, translate=True)\n",
    "        naive_rag_list = naive_rag_translated(instances, file_path, databases)\n",
    "        naive_rag_score = ragas_with_params(naive_rag_list, questions_translated, naive_rag_list, refs)\n",
    "        score = {\n",
    "            \"text_splitter\": text_splitter,\n",
    "            \"embedding model\": embedding,\n",
    "            \"score\": naive_rag_score\n",
    "        }\n",
    "        list_of_scores.append(score)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/adrianfolge/Documents/lokal:skole/Master/master_folder/eval_data/embeddings_and_text_splitters_FAISS_translated.txt', 'w') as f:\n",
    "    for item in list_of_scores:\n",
    "        f.write(str(item) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "data = {\n",
    "    'Embedding model': ['mpnet', 'e5', 'Open AI', 'mpnet', 'e5', 'Open AI'],\n",
    "    'Text splitter': ['Recursive', 'Recursive', 'Recursive', 'Character', 'Character', 'Character'],\n",
    "    'Context precision': [0.8500, 0.8000, 0.9000, 0.8500, 0.8500, 0.9000],\n",
    "    'Faithfulness': [0.9108, 0.9542, 0.9692, 0.8925, 0.9725, 0.9608],\n",
    "    'Answer relevancy': [0.8418, 0.8355, 0.8392, 0.8419, 0.8296, 0.8387],\n",
    "    'Context recall': [0.8000, 0.8250, 0.9250, 0.8500, 0.9000, 0.9250]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate average score for each row\n",
    "df['Average'] = df[['Context precision', 'Faithfulness', 'Answer relevancy', 'Context recall']].mean(axis=1)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(df.index, df['Average'], color='skyblue')\n",
    "plt.ylabel('Average Score')\n",
    "plt.title('Average Score for FAISS DB (English)')\n",
    "plt.xticks(df.index, df['Embedding model'] + ' - ' + df['Text splitter'], rotation=45)\n",
    "plt.ylim(0.8, 1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MASTER",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
