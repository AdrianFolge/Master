{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-03 09:33:47.247929: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import UnstructuredFileLoader, DirectoryLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import pandas as pd\n",
    "import re\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain import hub\n",
    "import os\n",
    "from langchain.prompts import PromptTemplate\n",
    "from deep_translator import GoogleTranslator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "references = load_dataset('csv', data_files=r'/Users/adrianfolge/Documents/lokal:skole/Master/data/synthetic_data/vol2_questions_and_answers.csv', split=\"train[:400]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.44it/s]\n",
      "Created a chunk of size 1147, which is longer than the specified 500\n",
      "Created a chunk of size 1570, which is longer than the specified 500\n",
      "Created a chunk of size 639, which is longer than the specified 500\n",
      "Created a chunk of size 610, which is longer than the specified 500\n",
      "Created a chunk of size 1008, which is longer than the specified 500\n",
      "Created a chunk of size 545, which is longer than the specified 500\n",
      "Created a chunk of size 536, which is longer than the specified 500\n",
      "Created a chunk of size 583, which is longer than the specified 500\n",
      "Created a chunk of size 1162, which is longer than the specified 500\n",
      "Created a chunk of size 607, which is longer than the specified 500\n",
      "Created a chunk of size 1206, which is longer than the specified 500\n",
      "Created a chunk of size 697, which is longer than the specified 500\n",
      "Created a chunk of size 734, which is longer than the specified 500\n",
      "Created a chunk of size 916, which is longer than the specified 500\n",
      "Created a chunk of size 916, which is longer than the specified 500\n",
      "Created a chunk of size 509, which is longer than the specified 500\n",
      "Created a chunk of size 603, which is longer than the specified 500\n",
      "Created a chunk of size 519, which is longer than the specified 500\n",
      "Created a chunk of size 519, which is longer than the specified 500\n",
      "Created a chunk of size 634, which is longer than the specified 500\n",
      "Created a chunk of size 522, which is longer than the specified 500\n",
      "Created a chunk of size 513, which is longer than the specified 500\n",
      "Created a chunk of size 930, which is longer than the specified 500\n",
      "Created a chunk of size 530, which is longer than the specified 500\n",
      "Created a chunk of size 665, which is longer than the specified 500\n",
      "Created a chunk of size 518, which is longer than the specified 500\n",
      "Created a chunk of size 518, which is longer than the specified 500\n",
      "Created a chunk of size 590, which is longer than the specified 500\n",
      "Created a chunk of size 590, which is longer than the specified 500\n",
      "Created a chunk of size 923, which is longer than the specified 500\n",
      "Created a chunk of size 923, which is longer than the specified 500\n",
      "Created a chunk of size 638, which is longer than the specified 500\n",
      "Created a chunk of size 504, which is longer than the specified 500\n",
      "Created a chunk of size 662, which is longer than the specified 500\n",
      "Created a chunk of size 564, which is longer than the specified 500\n",
      "Created a chunk of size 525, which is longer than the specified 500\n",
      "Created a chunk of size 535, which is longer than the specified 500\n",
      "Created a chunk of size 799, which is longer than the specified 500\n",
      "Created a chunk of size 548, which is longer than the specified 500\n",
      "Created a chunk of size 671, which is longer than the specified 500\n",
      "Created a chunk of size 535, which is longer than the specified 500\n",
      "Created a chunk of size 724, which is longer than the specified 500\n",
      "Created a chunk of size 2724, which is longer than the specified 500\n",
      "Created a chunk of size 2250, which is longer than the specified 500\n",
      "Created a chunk of size 2864, which is longer than the specified 500\n"
     ]
    }
   ],
   "source": [
    "loader = DirectoryLoader('data/', glob=\"**/*.pdf\", show_progress=True, loader_cls=UnstructuredFileLoader)\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "databases = {}\n",
    "for doc in documents:\n",
    "    source = doc.metadata['source']\n",
    "    match = re.search(r'\\/([A-Za-z_]+)\\.pdf', source)\n",
    "    if match:\n",
    "        municipality_name = match.group(1)\n",
    "    docs = text_splitter.split_documents([doc])\n",
    "    for document in docs:\n",
    "        page_content = document.page_content\n",
    "        translated_content = GoogleTranslator(source='no', target='en').translate(text=page_content)\n",
    "        document.page_content = translated_content\n",
    "    for index, doc in enumerate(docs):\n",
    "        if isinstance(doc.page_content, type(None)):\n",
    "            docs[index].page_content = \"\"\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "    db = FAISS.from_documents(docs, embeddings)\n",
    "    databases[municipality_name] = db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "prompt.messages\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_answers = []\n",
    "for i in range(400):\n",
    "    question = references[\"spørsmål\"][i]\n",
    "    translated_query = GoogleTranslator(source='no', target='en').translate(text=question)\n",
    "    kommunenavn = references[\"kommunenavn\"][i]\n",
    "    db = databases[kommunenavn]\n",
    "    retriever = db.as_retriever()\n",
    "\n",
    "    tool = create_retriever_tool(\n",
    "        retriever,\n",
    "        \"search_state_of_union\",\n",
    "        \"Searches and returns excerpts from the 2022 State of the Union.\",\n",
    "    )\n",
    "    tools = [tool]\n",
    "\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    agent_executor = AgentExecutor(agent=agent, tools=tools)\n",
    "    \n",
    "    result = agent_executor.invoke(\n",
    "        {\n",
    "            \"input\": f\"{translated_query}\"\n",
    "        }\n",
    "    )\n",
    "    translated_answer = GoogleTranslator(source='en', target='no').translate(text=result[\"output\"])\n",
    "    list_of_answers.append(translated_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = list_of_answers\n",
    "refs = references[\"svar\"]\n",
    "content_list = []\n",
    "\n",
    "# Choose the LLM that will drive the agent\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-1106\")\n",
    "\n",
    "# Define the prompt template\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"\"\"Task: Answer Evaluation\n",
    "You are given a reference answer and a predicted answer. Your task is to determine whether the predicted answer matches the reference answer correctly. It does not have to be an exact match, but it should be somewhat the same.\n",
    "- The reference answer is the correct answer.\n",
    "- The predicted answer is the answer generated by a model or provided by a user.\n",
    "Your response should indicate whether the predicted answer is correct or not.\n",
    "Reference answer: {reference}\n",
    "Predicted answer: {prediction}\n",
    "Is the predicted answer correct? [Yes/No]\n",
    "agent_scratchpad: This is the scratchpad where you can store intermediate information.\"\"\",\n",
    "    input_variables=[\"prediction\", \"reference\"]\n",
    ")\n",
    "chain = prompt_template | llm\n",
    "\n",
    "for num in range(400):\n",
    "    score = chain.invoke(\n",
    "        {\n",
    "            \"reference\": refs[num],\n",
    "            \"prediction\": list_of_answers[num],\n",
    "        }\n",
    "    )\n",
    "    content_list.append(score.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 'Yes': 230\n",
      "Number of 'No': 146\n"
     ]
    }
   ],
   "source": [
    "count_yes = content_list.count('Yes')\n",
    "count_no = content_list.count('No')\n",
    "\n",
    "# Displaying the counts\n",
    "print(\"Number of 'Yes':\", count_yes)\n",
    "print(\"Number of 'No':\", count_no)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MASTER",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
