{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import UnstructuredFileLoader, DirectoryLoader\n",
    "import pandas as pd\n",
    "import re\n",
    "import re\n",
    "import uuid\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from tqdm.notebook import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Created a chunk of size 1147, which is longer than the specified 500\n",
      "Created a chunk of size 1570, which is longer than the specified 500\n",
      "Created a chunk of size 639, which is longer than the specified 500\n",
      "Created a chunk of size 610, which is longer than the specified 500\n",
      "Created a chunk of size 1008, which is longer than the specified 500\n",
      "Created a chunk of size 545, which is longer than the specified 500\n",
      "Created a chunk of size 536, which is longer than the specified 500\n",
      "Created a chunk of size 583, which is longer than the specified 500\n",
      "Created a chunk of size 1162, which is longer than the specified 500\n",
      "Created a chunk of size 607, which is longer than the specified 500\n",
      "Created a chunk of size 1206, which is longer than the specified 500\n",
      "Created a chunk of size 697, which is longer than the specified 500\n",
      "Created a chunk of size 734, which is longer than the specified 500\n",
      "Created a chunk of size 916, which is longer than the specified 500\n",
      "Created a chunk of size 916, which is longer than the specified 500\n",
      "Created a chunk of size 509, which is longer than the specified 500\n",
      "Created a chunk of size 603, which is longer than the specified 500\n",
      "Created a chunk of size 519, which is longer than the specified 500\n",
      "Created a chunk of size 519, which is longer than the specified 500\n",
      "Created a chunk of size 634, which is longer than the specified 500\n",
      "Created a chunk of size 522, which is longer than the specified 500\n",
      "Created a chunk of size 513, which is longer than the specified 500\n",
      "Created a chunk of size 930, which is longer than the specified 500\n",
      "Created a chunk of size 530, which is longer than the specified 500\n",
      "Created a chunk of size 665, which is longer than the specified 500\n",
      "Created a chunk of size 518, which is longer than the specified 500\n",
      "Created a chunk of size 518, which is longer than the specified 500\n",
      "Created a chunk of size 590, which is longer than the specified 500\n",
      "Created a chunk of size 590, which is longer than the specified 500\n",
      "Created a chunk of size 923, which is longer than the specified 500\n",
      "Created a chunk of size 923, which is longer than the specified 500\n",
      "Created a chunk of size 638, which is longer than the specified 500\n",
      "Created a chunk of size 504, which is longer than the specified 500\n",
      "Created a chunk of size 662, which is longer than the specified 500\n",
      "Created a chunk of size 564, which is longer than the specified 500\n",
      "Created a chunk of size 525, which is longer than the specified 500\n",
      "Created a chunk of size 535, which is longer than the specified 500\n",
      "Created a chunk of size 799, which is longer than the specified 500\n",
      "Created a chunk of size 548, which is longer than the specified 500\n",
      "Created a chunk of size 671, which is longer than the specified 500\n",
      "Created a chunk of size 535, which is longer than the specified 500\n",
      "Created a chunk of size 724, which is longer than the specified 500\n",
      "Created a chunk of size 2724, which is longer than the specified 500\n",
      "Created a chunk of size 2250, which is longer than the specified 500\n",
      "Created a chunk of size 2864, which is longer than the specified 500\n"
     ]
    }
   ],
   "source": [
    "loader = DirectoryLoader('data/', glob=\"**/*.pdf\", show_progress=True, loader_cls=UnstructuredFileLoader)\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "databases = {}\n",
    "for doc in documents:\n",
    "    source = doc.metadata['source']\n",
    "    match = re.search(r'\\/([A-Za-z_]+)\\.pdf', source)\n",
    "    if match:\n",
    "        municipality_name = match.group(1)\n",
    "    docs = text_splitter.split_documents([doc])\n",
    "    databases[municipality_name] = docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_queries(\n",
    "    corpus,\n",
    "    num_questions_per_chunk=1,\n",
    "    prompt_template=None,\n",
    "    verbose=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Automatisk generer hypotetiske spørsmål som kan besvares med dokumentet i korpuset.\n",
    "    \"\"\"\n",
    "    llm = OpenAI(model='gpt-3.5-turbo')\n",
    "\n",
    "    prompt_template = prompt_template or \"\"\"\\\n",
    "    Kontekstinformasjonen er nedenfor.\n",
    "\n",
    "    ---------------------\n",
    "    {context_str}\n",
    "    ---------------------\n",
    "\n",
    "    Gitt kontekstinformasjonen og ikke tidligere kunnskap.\n",
    "    Generer bare spørsmål basert på forespørselen nedenfor.\n",
    "\n",
    "    Du er en lærer/professor. \n",
    "    Oppgaven din er å sette opp {num_questions_per_chunk} spørsmål for en kommende quiz/eksamen. \n",
    "    Du skal også besvare spørsmålet.\n",
    "    Spørsmålene bør være varierte i naturen på tvers av dokumentet. \n",
    "    Begrens spørsmålene og svarene til den kontekstinformasjonen som er gitt.\"\n",
    "    \"\"\"    \n",
    "    queries = {}\n",
    "    relevant_docs = {}\n",
    "    for municipality_name, text_chunks in tqdm(corpus.items()):\n",
    "        for chunk in text_chunks:\n",
    "            query = prompt_template.format(context_str=chunk, num_questions_per_chunk=num_questions_per_chunk)\n",
    "            response = llm.complete(query)\n",
    "\n",
    "            result = str(response).strip().split(\"\\n\")\n",
    "            questions = [\n",
    "                re.sub(r\"^\\d+[\\).\\s]\", \"\", question).strip() for question in result\n",
    "            ]\n",
    "            questions = [question for question in questions if len(question) > 0]\n",
    "            for question in questions:\n",
    "                question_id = str(uuid.uuid4())\n",
    "                queries[question_id] = question\n",
    "                relevant_docs[question_id] = [municipality_name]\n",
    "    return queries, relevant_docs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e45b01aae62340f59ec3ab99b30b1072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_queries, train_relevant_docs = generate_queries(\n",
    "    databases,\n",
    "    num_questions_per_chunk=1,\n",
    "    prompt_template=None,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   nøkkel  \\\n",
      "0    d8d519f8-0a70-4341-9c50-4a3ada658be4   \n",
      "1    e2125ad3-2222-43e0-8f48-65e8ab6cc8a6   \n",
      "2    c0dbe2c5-7f80-437e-8ede-2a08b6ed0a4b   \n",
      "3    e372dea3-0a38-491d-beec-15a951895f7f   \n",
      "4    8455b7ad-037f-4e5d-9202-12dcf94963d9   \n",
      "..                                    ...   \n",
      "436  e1516bb5-cece-40b6-9535-0d3302c266fb   \n",
      "437  3344451a-d97d-44bc-a658-2dca8e0af527   \n",
      "438  7b5bd562-d799-4633-bccc-ba6a4bba35cf   \n",
      "439  9ab412a5-fea2-4844-ad05-549a69684ef1   \n",
      "440  cee27819-2c3a-4c3b-9a67-7231fa7301f4   \n",
      "\n",
      "                                              spørsmål  \\\n",
      "0    Hva er datoen for vedtaket av Kommunedelplan f...   \n",
      "1    Hvor kan man finne felles bestemmelser i dokum...   \n",
      "2     Hva er hovedtemaet for avsnitt 3.6 i dokumentet?   \n",
      "3    Hva er emnet for kapittel 4 i dokumentet fra K...   \n",
      "4    Hva er formålet med hensynssonene i dokumentet...   \n",
      "..                                                 ...   \n",
      "436  Hvilken side av dokumentet er vi på, ifølge ko...   \n",
      "437  Hva er maksimalt antall boenheter som tillates...   \n",
      "438  Hvilken side av dokumentet er vi på ifølge kon...   \n",
      "439  Hva er kravene til sikringssone frisikt, H140_...   \n",
      "440  Hva skal være tinglyst til naboeiendommen gnr/...   \n",
      "\n",
      "                                                  svar  \n",
      "0                                           26.8.2021.  \n",
      "1    Man kan finne felles bestemmelser på side 3 i ...  \n",
      "2    Hovedtemaet for avsnitt 3.6 er offentlige områ...  \n",
      "3                                Bebyggelse og anlegg.  \n",
      "4    Formålet med hensynssonene er å regulere ulike...  \n",
      "..                                                 ...  \n",
      "436  Vi er på side 3 av 5, ifølge kontekstinformasj...  \n",
      "437  Totalt antall boenheter skal ikke overstige 30...  \n",
      "438  Vi er på side 4 av 5 ifølge kontekstinformasjo...  \n",
      "439  H140 er frisiktområde i avkjørsel og kryss, so...  \n",
      "440            Bruksrett for parkeringsplasser i f_P2.  \n",
      "\n",
      "[441 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "data_list = list(train_queries.items())\n",
    "\n",
    "# Initialiser lister for kolonner\n",
    "keys = []\n",
    "questions = []\n",
    "answers = []\n",
    "\n",
    "# Loop gjennom dataen og separer nøkler, spørsmål og svar\n",
    "for i in range(0, len(data_list), 2):\n",
    "    key = data_list[i][0]\n",
    "    question = data_list[i][1].split(': ')[1]\n",
    "    answer = data_list[i+1][1].split(': ')[1]\n",
    "    keys.append(key)\n",
    "    questions.append(question)\n",
    "    answers.append(answer)\n",
    "\n",
    "# Lag en DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'nøkkel': keys,\n",
    "    'spørsmål': questions,\n",
    "    'svar': answers\n",
    "})\n",
    "\n",
    "df['kommunenavn'] = [train_relevant_docs[key][0] for key in df['nøkkel']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe uten nøkkelkolonnen er lagret som dataframe.csv\n"
     ]
    }
   ],
   "source": [
    "# Fjern nøkkelkolonnen fra DataFrame\n",
    "df_without_key = df.drop(columns=['nøkkel'])\n",
    "\n",
    "# Lagre DataFrame til en CSV-fil uten nøkkelkolonnen\n",
    "df_without_key.to_csv('/Users/adrianfolge/Documents/lokal:skole/Master/data/synthetic_data/vol2_questions_and_answers.csv', index=False)\n",
    "\n",
    "print(\"Dataframe uten nøkkelkolonnen er lagret som dataframe.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'26.8.2021.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_without_key[\"svar\"][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MASTER",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
