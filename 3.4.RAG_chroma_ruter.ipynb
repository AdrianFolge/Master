{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import UnstructuredFileLoader, DirectoryLoader\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "import os\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.43it/s]\n",
      "Created a chunk of size 1147, which is longer than the specified 500\n",
      "Created a chunk of size 1570, which is longer than the specified 500\n",
      "Created a chunk of size 639, which is longer than the specified 500\n",
      "Created a chunk of size 610, which is longer than the specified 500\n",
      "Created a chunk of size 1008, which is longer than the specified 500\n",
      "Created a chunk of size 545, which is longer than the specified 500\n",
      "Created a chunk of size 536, which is longer than the specified 500\n",
      "Created a chunk of size 583, which is longer than the specified 500\n",
      "Created a chunk of size 1162, which is longer than the specified 500\n",
      "Created a chunk of size 607, which is longer than the specified 500\n",
      "Created a chunk of size 1206, which is longer than the specified 500\n",
      "Created a chunk of size 697, which is longer than the specified 500\n",
      "Created a chunk of size 734, which is longer than the specified 500\n",
      "Created a chunk of size 916, which is longer than the specified 500\n",
      "Created a chunk of size 916, which is longer than the specified 500\n",
      "Created a chunk of size 509, which is longer than the specified 500\n",
      "Created a chunk of size 603, which is longer than the specified 500\n",
      "Created a chunk of size 519, which is longer than the specified 500\n",
      "Created a chunk of size 519, which is longer than the specified 500\n",
      "Created a chunk of size 634, which is longer than the specified 500\n",
      "Created a chunk of size 522, which is longer than the specified 500\n",
      "Created a chunk of size 513, which is longer than the specified 500\n",
      "Created a chunk of size 930, which is longer than the specified 500\n",
      "Created a chunk of size 530, which is longer than the specified 500\n",
      "Created a chunk of size 665, which is longer than the specified 500\n",
      "Created a chunk of size 518, which is longer than the specified 500\n",
      "Created a chunk of size 518, which is longer than the specified 500\n",
      "Created a chunk of size 590, which is longer than the specified 500\n",
      "Created a chunk of size 590, which is longer than the specified 500\n",
      "Created a chunk of size 923, which is longer than the specified 500\n",
      "Created a chunk of size 923, which is longer than the specified 500\n",
      "Created a chunk of size 638, which is longer than the specified 500\n",
      "Created a chunk of size 504, which is longer than the specified 500\n",
      "Created a chunk of size 662, which is longer than the specified 500\n",
      "Created a chunk of size 564, which is longer than the specified 500\n",
      "Created a chunk of size 525, which is longer than the specified 500\n",
      "Created a chunk of size 535, which is longer than the specified 500\n",
      "Created a chunk of size 799, which is longer than the specified 500\n",
      "Created a chunk of size 548, which is longer than the specified 500\n",
      "Created a chunk of size 671, which is longer than the specified 500\n",
      "Created a chunk of size 535, which is longer than the specified 500\n",
      "Created a chunk of size 724, which is longer than the specified 500\n",
      "Created a chunk of size 2724, which is longer than the specified 500\n",
      "Created a chunk of size 2250, which is longer than the specified 500\n",
      "Created a chunk of size 2864, which is longer than the specified 500\n"
     ]
    }
   ],
   "source": [
    "loader = DirectoryLoader('data/', glob=\"**/*.pdf\", show_progress=True, loader_cls=UnstructuredFileLoader)\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "embeddings = SentenceTransformerEmbeddings(model_name='sentence-transformers/paraphrase-multilingual-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('csv', data_files=r'C:\\Users\\adrianhf\\Documents\\test\\Master\\data\\synthetic_data\\question_with_answers.csv', split=\"train[:10]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"RuterNorway/Llama-2-13b-chat-norwegian\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"RuterNorway/Llama-2-13b-chat-norwegian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_from_model = []\n",
    "for i in range(10):\n",
    "    query = dataset[\"Question\"][i]\n",
    "    found_docs = db.similarity_search(query)\n",
    "    context = found_docs[0].page_content\n",
    "    input = f\"Spørsmål: {query} context: {context}\"\n",
    "    instruction = \"Svar på spørsmålet basert på det som står i 'context'\"\n",
    "    prompt_template=f'''### Instruction: {instruction}\n",
    "    ### Input: {input}\n",
    "    ### Response:\n",
    "    '''\n",
    "    print(\"\\n\\n*** Generate:\")\n",
    "    inputs = tokenizer(prompt_template, return_tensors=\"pt\")\n",
    "\n",
    "    out = model.generate(**inputs, max_new_tokens=200)\n",
    "    print(tokenizer.decode(out[0], skip_special_tokens=True))\n",
    "\n",
    "    # Pipeline prompting\n",
    "    print(\"\\n\\n*** Pipeline:\\n\\n\")\n",
    "    pipe = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        do_sample=True,\n",
    "        tokenizer=tokenizer,\n",
    "        max_new_tokens=512,\n",
    "        temperature=0.7,\n",
    "        top_p=0.95,\n",
    "        repetition_penalty=1.15\n",
    "    )\n",
    "    print(pipe(prompt_template)[0]['generated_text'][len(prompt_template):])\n",
    "    answers_from_model.append(pipe(prompt_template)[0]['generated_text'][len(prompt_template):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For hver manglende oppstillingsplass betaler tiltakshaver til enhver tid gjeldende frikjøpsbeløp til Kristiansund kommune. Frikjøpsbeløpet er for 2020 NOK 360 000 per oppstillingsplass for bil og NOK 41 000 per oppstillings- plass for sykkel. Beløpet kan prisjusteres årlig som del av budsjettbehandlingen. Innbetalte midler plasseres i kommunalt fond som gis betegnelsen ”Fond til parkeringsformål for Kristiansund kommune”. Fondets midler med renter disponeres av Kristiansund kommune. Fondets midler skal kun brukes til grunnerverv og opparbeid- else for offentlig parkeringsanlegg for bil og/eller sykkel, med tilhørende infrastruktur.\n"
     ]
    }
   ],
   "source": [
    "# Convert the list to a pandas DataFrame\n",
    "df = pd.DataFrame(answers_from_model, columns=['Text'])\n",
    "\n",
    "# Specify the file path\n",
    "file_path = \"C:\\\\Users\\\\adrianhf\\\\Documents\\\\test\\\\Master\\\\data\\\\Results\\\\Chroma_answers_from_model.csv\"\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "df.to_csv(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MASTER",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
